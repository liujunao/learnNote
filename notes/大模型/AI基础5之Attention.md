# 一、Encoder-Decoder 和 Seq2Seq

https://easyai.tech/ai-definition/encoder-decoder-seq2seq/







# 二、Word embedding

https://easyai.tech/ai-definition/word-embedding/

2 种主流的 word embedding 算法：

- Word2vec：https://easyai.tech/ai-definition/word2vec/
- GloVe：https://www.fanyeong.com/2018/02/19/glove-in-detail/



# 三、Attention 机制

https://easyai.tech/ai-definition/attention/

- 特点：
    - Attention机制每一步计算不依赖于上一步的计算结果，因此可以和CNN一样并行处理
    - Attention 是挑重点，就算文本比较长，也能从中间抓住重点，不丢失重要的信息

---

Attention 类型总结：https://zhuanlan.zhihu.com/p/35739040



# 四、Self-Attention 机制

- 介绍：https://juejin.cn/post/7125629962769399838

- 图解：https://zhuanlan.zhihu.com/p/686560602

---

更完善的解释：https://imzhanghao.com/2021/09/15/self-attention-multi-head-attention/

