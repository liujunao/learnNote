# 一、供应链

## 1、系统总体架构

``` mysql
graph TB
    subgraph 基础设施层
        I1[Kubernetes集群]
        I2[Service Mesh]
        I3[分布式存储]
    end
    
    subgraph 核心服务层
        C1[库存服务] -->|状态同步| C2[仓储服务]
        C2 -->|任务下发| C3[调度服务]
        C3 -->|指令传输| C4[设备控制服务]
        C1 -->|事件发布| C5[消息中心]
    end
    
    subgraph 支撑系统
        S1[监控告警] -->|指标采集| S2[Prometheus]
        S3[日志采集] -->|日志传输| S4[ELK Stack]
        S5[分布式追踪] -->|Span数据| S6[Jaeger]
    end
    
    subgraph 接入层
        A1[API网关] -->|路由| A2[负载均衡]
        A2 -->|服务发现| C1
        A2 -->|服务发现| C2
    end
```

## 2、库存服务

### 2.1 简述

- 架构特性：

    - **单元化部署**：按区域划分库存单元（华北/华东/华南）
    - **读写分离设计**

- 关键技术：

    - **分布式锁**：改进版Redlock实现（增加本地缓存降低Redis压力）

        > 解决高并发下的库存扣减问题，避免超卖，并且保证补货与销售操作的有序性
        >
        > 时钟漂移
        >
        > 通过分桶或分段锁来减少热点商品的竞争

    - **库存快照**：基于RocksDB的本地状态持久化

        > 为了快速恢复或查询历史状态，比如在系统崩溃后恢复数据，或者进行对账

    - **变更流水**：通过CDC(binlog Kafka)同步至数据仓库

        > 追踪库存变化的详细记录，用于审计、对账或补偿操作
        >
        > 监控数据库的binlog，将变更事件发送到Kafka，再由消费者处理到数据仓库或ES
        >
        > 需要强调**顺序性和幂等性**处理，避免重复或丢失数据

### 2.2 库存事务处理

- **分布式事务方案**

    > - **幂等性保障**：通过全局事务ID（txId）实现重复请求过滤
    > - **异步重试**：失败操作进入延迟队列，按指数退避策略重试
    > - **状态跟踪**：Redis存储事务状态机

    ```
    // 库存扣减的Saga模式实现
    public class InventorySaga {
        @SagaStart
        public void deductInventory(Long skuId, Integer count) {
            // Step1: 预占库存
            inventoryService.tempDeduct(skuId, count); 
            
            // Step2: 创建订单
            orderService.createOrder(...);
            
            // Compensation:
            inventoryService.cancelDeduct(skuId, count);
        }
    }
    
    本地库存预扣：提前将库存分配到边缘节点
    异步化扣减：先返回成功再异步持久化
    库存预热：提前加载热点数据到缓存
    ```

- **性能优化**：

    - 热点库存处理：本地缓存+Redis分片+数据库批量合并

        > **本地缓存消峰**(Guava令牌桶实现)
        >
        > **分段锁优化**(将库存拆分为10个分段)
        >
        > **批量合并提交**(合并5ms内的库存变更)

    - 批量操作接口：合并短时间内的多次库存变更

### 2.3 存储架构设计

- **核心存储矩阵**：

    | 数据类型 | 存储方案 | 技术特性          |
    | :------- | :------- | :---------------- |
    | 实时库存 | TiDB集群 | 强一致/HATP       |
    | 操作日志 | Kafka+ES | 顺序写入/快速检索 |
    | 设备状态 | TDengine | 时序数据压缩      |
    | 库存快照 | RocksDB  | 本地持久化        |

- **分库分表策略**：

    ```
    -- 库存表分片规则
    CREATE TABLE inventory_${tenant}_${region} (
      sku_id BIGINT,
      warehouse_id INT,
      stock INT,
      PRIMARY KEY(sku_id, warehouse_id)
    ) PARTITION BY HASH(warehouse_id) PARTITIONS 16;
    ```

### 2.4 缓存体系设计

- **三级缓存架构**：

    ```
    本地缓存(Caffeine) → 分布式缓存(Redis) → 持久层(TiDB)
    ```

- **缓存更新策略**：

    ``` java
    // 库存缓存更新示例
    @Cacheable(value = "inventory", key = "#skuId")
    public Inventory getInventory(Long skuId) {
        return dao.get(skuId);
    }
    
    @CacheEvict(value = "inventory", key = "#skuId")
    public void updateInventory(Long skuId) {
        // 更新逻辑
    }
    ```

### 2.5 典型库存操作流程

1. 获取分布式锁（SKU级别）
2. 记录变更预写日志（WAL）
3. 执行数据库更新
4. 生成变更事件（CDC）
5. 释放锁并更新快照
6. 异步处理下游事件

### 2.6 性能优化对比

| 优化前指标      | 优化后指标       | 优化手段                   |
| :-------------- | :--------------- | :------------------------- |
| 锁竞争率：35%   | 锁竞争率：8%     | 分段锁+本地缓存优化        |
| 快照延迟：15秒  | 快照延迟：3秒    | 内存表分片+并行持久化      |
| 流水处理TPS：5K | 流水处理TPS：50K | Kafka批量压缩+消费者组优化 |
| 恢复时间：5分钟 | 恢复时间：30秒   | 快照预热+增量日志回放      |

## 3、仓储调度服务

**架构设计**：

- 任务队列分级：

    | 队列等级 | 响应要求 | 典型场景 |
    | :------- | :------- | :------- |
    | L0       | <100ms   | 紧急补货 |
    | L1       | <1s      | 常规补货 |
    | L2       | <5s      | 库存盘点 |

- 设备通信协议栈：

    ``` 
    TCP长连接 → Protobuf协议编解码 → 指令优先级队列 → 应答确认机制
    ```

## 4、前置仓管理系统

### 4.1 简述

- **核心组件**：
    - 容量监控服务：实时计算仓容水位
    - 温控监管服务：对接IoT设备数据流
    - 动态路由服务：与配送系统实时联动
- **数据同步机制**：
    - 前置仓终端->>边缘计算节点: 上报库存变更
    - 边缘计算节点->>区域中心: 批量同步数据(每5s)
    - 区域中心->>中央库存服务: 最终一致性同步
    - 中央库存服务-->>前置仓终端: 反向配置更新

### 4.2 服务治理体系

- **核心能力矩阵**：

    | 治理维度 | 技术方案         | 关键指标         |
    | :------- | :--------------- | :--------------- |
    | 流量控制 | Sentinel集群流控 | QPS阈值/异常比例 |
    | 服务容错 | Resilience4j熔断 | 失败率阈值       |
    | 灰度发布 | Istio流量染色    | 版本分流比例     |
    | 异常隔离 | Hystrix舱壁模式  | 线程池隔离度     |

- **服务网格集成**：

    ```
    # Istio VirtualService配置示例
    apiVersion: networking.istio.io/v1alpha3
    kind: VirtualService
    metadata:
      name: inventory-vs
    spec:
      hosts:
      - inventory-service
      http:
      - route:
        - destination:
            host: inventory-service
            subset: v1
        mirror:
          host: inventory-service
          subset: v2
        retries:
          attempts: 3
          retryOn: 5xx
    ```

# 二、基础

## 1、spring

### 1.1 Bean 的作用域

Singleton、Prototype、Request 等

Bean 懒加载（`@Lazy`）与作用域选择

### 1.2 Bean 创建与循环依赖

Bean 的创建流程：实例化 → 属性填充 → 初始化 → 销毁



Spring 如何解决循环依赖？

三级缓存机制（SingletonObjects、EarlySingletonObjects、SingletonFactories）

三级缓存的具体作用是什么？



### 1.3 事务管理

- 事务传播机制（PROPAGATION_REQUIRED、PROPAGATION_REQUIRES_NEW 等）。
- 事务隔离级别与数据库隔离级别的关系。
- Spring 事务的实现原理（基于 AOP 和 TransactionManager）。



`@Transactional` 注解在哪些情况下会失效？

什么是 Spring 的声明式事务？底层如何实现？



### 1.4 性能优化

- 异步请求处理（`@Async`、`DeferredResult`、`Callable`）。
- 静态资源缓存配置



### 1.5 设计模式应用

- 工厂模式（BeanFactory）、代理模式（AOP）、模板方法模式（JdbcTemplate）。
- 观察者模式（ApplicationEvent 和 ApplicationListener）



### 1.6 springboot

Spring Boot 自动配置的原理是什么？





## 2、mybatis

### 2.1 核心组件

- `SqlSessionFactory`：全局单例，用于创建 `SqlSession`。
- `SqlSession`：执行SQL、管理事务的会话（线程不安全，需每次请求创建）。
- `Mapper` 接口：通过动态代理绑定到XML或注解的SQL。
- `Executor`：SQL执行器（Simple、Reuse、Batch）

MyBatis 如何实现 Mapper 接口的？动态代理的作用是什么？



### 2.2 SQL 映射与动态 SQL

1. **参数与结果映射**

    - `#{}` 和 `${}` 的区别：预编译（防SQL注入） vs. 字符串替换

        > 如何防止 SQL 注入？

    - `@Param` 注解的作用：多参数映射。

    - `resultMap`：自定义结果集映射（处理复杂对象、关联查询）

        > `<resultMap>` 的作用是什么？如何映射复杂对象（如嵌套对象）？

1. **动态 SQL 标签**
    - `<if>`、`<choose>/<when>/<otherwise>`：条件分支
    - `<foreach>`：遍历集合（IN查询、批量插入）
    - `<where>`、`<set>`、`<trim>`：智能处理SQL片段

### 2.3 缓存机制

1. **一级缓存（本地缓存）**
    - 默认开启，`SqlSession` 级别，执行`commit`、`close`或`clearCache`后失效
    - 问题：重复查询可能命中缓存，导致脏读（需注意作用域）
2. **二级缓存（全局缓存）**
    - `Mapper` 级别，需手动配置（`<cache>`标签或`@CacheNamespace`）
    - 缓存策略：LRU、FIFO、SOFT/WEAK（内存敏感场景）
    - 注意事项：序列化、事务提交后才生效、多表关联可能脏读

二级缓存可能导致什么问题？



#### 2.4 与 Spring 集成

1. **MyBatis-Spring 整合**
    - 配置方式：`SqlSessionFactoryBean`、`MapperScannerConfigurer`。
    - `SqlSessionTemplate`：线程安全的`SqlSession`封装。
    - 事务管理：由Spring的`DataSourceTransactionManager`控制。
2. **Mapper 接口原理**
    - 动态代理：通过`MapperProxy`将接口方法绑定到XML或注解SQL。
    - `@MapperScan`：自动扫描并注册Mapper接口

MyBatis 如何与 Spring 集成？关键配置类有哪些？



### 2.5 分页实现

- 物理分页：数据库方言（如MySQL的`LIMIT`）。
- 逻辑分页：`RowBounds`（内存分页，不推荐大数据量）。
- 插件分页：PageHelper（自动改写SQL）

如何实现分页查询？PageHelper 的原理是什么？



### 2.6 延迟加载

延迟加载（懒加载）：`fetchType="lazy"`，需开启全局配置

延迟加载的原理是什么？如何配置？



### 2.7 插件

MyBatis 插件可以拦截哪些对象？如何实现一个自定义插件？



### 2.8 批量插入

如何优化 MyBatis 的批量插入性能？



### 2.9 N+1 问题

什么是 N+1 查询问题？如何解决？





## 3、设计模式





## 4、mysql

### 4.1 索引

B+ 树

聚簇索引、非聚簇索引

回表查询

覆盖索引、最左前缀原则、索引下推（ICP）

避免全表扫描：通过 `EXPLAIN` 分析执行计划，关注 `rows`、`key`、`type`。

分页优化：避免 `LIMIT 100000,10`，改用 `WHERE id > 100000 LIMIT 10`

### 4.2 锁

- **事务隔离级别**

- **锁机制**：
    - 行锁（共享锁 S、排他锁 X）、间隙锁（Gap Lock）、临键锁（Next-Key Lock）。
    - 死锁检测与处理：`SHOW ENGINE INNODB STATUS`。

**高频问题**：

- 什么是幻读？如何解决？（间隙锁）
- 乐观锁 vs 悲观锁的实现（版本号、`SELECT ... FOR UPDATE`）



什么是间隙锁？在库存扣减中如何避免幻读？



### 4.3 事务与 MVCC

InnoDB 的 MVCC 实现原理是什么？





### 4.4 高可用与扩展

- **主从复制**：
    - 异步复制、半同步复制（保证数据一致性）
    - 读写分离：通过代理（如 MyCat）或客户端分库分表
- **分库分表**：
    - 垂直拆分（按业务模块）、水平拆分（按用户ID、时间）
    - 问题：分布式事务（XA、Seata）、跨分片查询（全局二级索引）
- **高频问题**：
    - 分库分表后如何实现全局唯一ID？（雪花算法、Redis自增）



分库分表后，如何实现跨分片的排序和分页？

订单表数据量过大，如何设计分表策略？

Redis 和 MySQL 如何保证缓存与数据库的一致性？

主从复制延迟导致的数据不一致问题如何解决？

解释 Binlog 和 Redo Log 的区别与作用。



### 4.5 优化

如何优化一个慢查询（如 `SELECT * FROM orders WHERE user_id=100 ORDER BY create_time DESC LIMIT 10000,10`）？







### 4.6 应用

- **扣减一致性**：

    - **超卖问题**：通过事务+行锁（`SELECT ... FOR UPDATE`）或乐观锁（版本号）保证原子性。
    - **预扣库存**：下单时预扣库存，支付成功后实际扣减，超时未支付回滚。

    > 电商场景中，如何解决超卖问题？除了锁还有什么方案？

- **热点行优化**：

    - **批量扣减**：将单行库存拆分为多行（如库存分桶），减少锁竞争。
    - **异步队列**：通过消息队列（如 Kafka）削峰，异步处理库存更新。

- **高频问题**：

    - 如何设计一个支持高并发秒杀的库存系统？
    - 分桶库存的实现原理是什么？

- **事务一致性**：
    - 订单创建需保证：扣库存、生成订单、记录流水的事务原子性。
    - 最终一致性方案：TCC（Try-Confirm-Cancel）、本地消息表。
- **数据分片**：
    - 订单表按用户ID分片，避免单表过大。
    - 历史订单归档：按时间分区，冷热数据分离。
- **高频问题**：
    - 如何处理订单支付超时？（定时任务扫描+状态回滚）

- **复杂查询优化**：
    - 多表关联查询（订单、物流、库存）使用覆盖索引或冗余字段。
    - 聚合查询（如库存周转率）使用物化视图或预计算。
- **数据一致性**：
    - 分布式事务：跨库存、物流系统的数据同步（如基于 Binlog 的 CDC 技术）。
- **高频问题**：
    - 如何实时监控库存周转率？（定时任务+聚合表）

- **缓存结合**：
    - 读多写少场景（如商品详情）使用 Redis 缓存，缓存击穿/穿透/雪崩解决方案。
    - 库存缓存：Redis 预扣库存，异步同步到数据库。
- **容灾备份**：
    - 主从切换（Keepalived）、跨机房容灾（双活架构）。
    - 数据备份：全量备份（mysqldump）+ Binlog 增量恢复。



## 5、redis

### 5.1 分布式锁(redLock)

```java
// 改进版Redlock实现（Java示例）
public class InventoryLock {
    private static final String LOCK_PREFIX = "lock:sku:";
    private static final int LOCK_EXPIRE = 3000; // 3秒
    
    public boolean tryLock(String skuId, String requestId) {
        String key = LOCK_PREFIX + skuId;
        return redisTemplate.execute((RedisCallback<Boolean>) conn -> {
            // 使用Lua脚本保证原子性
            String luaScript = 
                "if redis.call('setnx', KEYS[1], ARGV[1]) == 1 then " +
                "   redis.call('pexpire', KEYS[1], ARGV[2]); " +
                "   return 1; " +
                "else " +
                "   return 0; " +
                "end";
            Object result = conn.eval(
                luaScript.getBytes(), 
                ReturnType.INTEGER, 
                1, 
                key.getBytes(), 
                requestId.getBytes(), 
                String.valueOf(LOCK_EXPIRE).getBytes()
            );
            return (Long)result == 1;
        });
    }
}
```

**多级锁优化策略**

```
graph TD
    A[请求进入] --> B{本地锁竞争}
    B -->|成功| C[Redis集群锁]
    B -->|失败| D[快速失败返回]
    C -->|成功| E[执行库存操作]
    C -->|失败| F[进入等待队列]
```

**工程实践要点**

- **锁粒度优化**：采用分段锁（如将SKU_1001拆分为SKU_1001_01~SKU_1001_10）
- **锁续期机制**：后台线程自动延长锁有效期
- **故障转移**：通过ZooKeeper实现锁服务高可用





### 5.2 Caffeine





### 5.3 数据结构与适用场景

- **String**：缓存、计数器（库存预扣）、分布式锁。
- **Hash**：存储对象（用户信息、商品详情）。
- **List**：消息队列、最新消息排行（如订单流水）。
- **Set**：唯一性集合（抽奖去重、共同好友）。
- **ZSet**：排行榜（商品销量、用户积分）。
- **BitMap**：签到统计、用户行为标记。
- **HyperLogLog**：UV 统计（近似去重计数）。
- **Stream**：消息队列（替代 List，支持多消费者组）

### 5.4 持久化机制

- **RDB（快照）**：
    - 定时生成数据快照，适合备份恢复。
    - 缺点：可能丢失最后一次快照后的数据。
- **AOF（追加日志）**：
    - 记录写操作命令，数据丢失风险低。
    - 重写机制（Rewrite）压缩日志文件。

### 5.5 高可用与集群

- **主从复制**：
    - 主节点（Master）异步复制到从节点（Slave），读写分离。
    - 问题：主从延迟导致数据不一致。
- **哨兵模式（Sentinel）**：
    - 监控主节点状态，自动故障转移（Failover）。
    - 缺点：无法横向扩展写能力。
- **Cluster 集群**：
    - 数据分片（16384 个槽），每个节点管理部分槽。
    - 客户端路由（`CRC16(key) % 16384`），支持动态扩缩容

### 5.6 性能与内存管理

- **内存淘汰策略**：
    - `volatile-lru`（最近最少使用）、`allkeys-lfu`（最不经常使用）等。
- **缓存穿透**：恶意查询不存在的数据。
    - 解决方案：布隆过滤器（Bloom Filter）、空值缓存。
- **缓存击穿**：热点数据过期后高并发请求穿透到数据库。
    - 解决方案：互斥锁（SETNX）、永不过期 + 异步更新。
- **缓存雪崩**：大量数据同时过期导致请求打到数据库。
    - 解决方案：随机过期时间、多级缓存（Redis + 本地缓存）

### 5.7 应用

#### **库存管理**

- **预扣库存**：
    - Redis 原子操作扣减库存（`DECR`），避免超卖。
    - 异步同步到数据库（通过消息队列确保最终一致性）。
- **库存分桶**：
    - 将库存拆分为多个 Key（如 `stock:product_1001:1` ~ `stock:product_1001:10`），分散热点。
- **库存回滚**：
    - 支付超时后，通过定时任务回滚 Redis 库存。

#### **2. 秒杀与高并发**

- **流量削峰**：
    - 使用 Redis 计数器限制用户请求频率。
    - 请求排队：Redis List 或 Stream 实现队列，异步处理订单。
- **分布式锁**：
    - 使用 `SET key value NX EX` 实现锁，避免重复下单。
    - 问题：锁超时导致并发问题（需结合 WatchDog 续期）。

#### **3. 订单与交易**

- **订单唯一性**：
    - 使用 Redis 全局唯一 ID（`INCR` 或雪花算法）。
- **购物车**：
    - 使用 Hash 存储用户购物车（`hset cart:user_1001 product_2001 2`）。

#### **4. 数据一致性**

- **缓存与数据库双写**：
    - 策略：先更新数据库，再删除缓存（延迟双删避免脏数据）。
    - 问题：缓存删除失败导致不一致（通过重试机制或订阅 Binlog 同步）。
- **最终一致性**：
    - 通过消息队列（如 Kafka）异步同步数据。

#### **5. 实时统计与监控**

- **排行榜**：
    - 使用 ZSet 实时统计商品销量 Top 10。
- **用户行为分析**：
    - 使用 BitMap 记录用户签到，HyperLogLog 统计 UV。

### 5.8 高频问题

1. Redis 如何实现分布式锁？有什么注意事项？
2. 缓存穿透、击穿、雪崩的区别及解决方案？
3. Redis 主从复制原理？数据不一致如何处理？
4. 如何用 Redis 实现一个延迟队列？
5. Redis Cluster 的扩容流程是什么？
6. 为什么 Redis 单线程性能依然高？（内存操作、非阻塞 I/O）
7. 如何保证 Redis 与 MySQL 的数据一致性？
8. 在秒杀场景中，如何用 Redis 优化库存扣减？
9. Redis 的持久化机制如何选择？RDB 和 AOF 的优缺点？
10. 如何用 Redis 实现一个简单的社交系统（关注、粉丝列表）？



如何通过 Redis 解决高并发、分布式锁等问题







## 6、hbase

### 6.1 库存快照

- **存储架构设计**

    ```
    graph LR
        A[实时库存] --> B[RocksDB本地存储]
        B --> C[定时快照]
        C --> D[OSS持久化存储]
        D --> E[快速恢复通道]
    ```

- **快照生成策略**

    ```python
    # 快照生成逻辑（Python伪代码）
    class SnapshotManager:
        def __init__(self):
            self.wal = WriteAheadLog()  # 预写日志
            self.current_snapshot = None
            
        def apply_operation(self, op):
            self.wal.append(op)  # 先写日志
            self.memtable.apply(op)  # 更新内存表
            
            # 触发快照条件
            if self.wal.size() > 100000 or time.time() - last_snapshot > 3600:
                self.create_snapshot()
        
        def create_snapshot(self):
            # 冻结内存表并持久化
            new_snapshot = self.memtable.freeze()
            self.save_to_oss(new_snapshot)
            self.current_snapshot = new_snapshot
            self.wal.clear()  # 清理旧日志
    ```

- **关键技术指标**

    | 指标项       | 目标值          | 实现手段                    |
    | :----------- | :-------------- | :-------------------------- |
    | 快照延迟     | <5秒（关键SKU） | 内存表分片冻结              |
    | 恢复时间     | <30秒（百万级） | 并行加载+索引优化           |
    | 存储压缩率   | >70%            | ZSTD压缩算法                |
    | 版本保留策略 | 最近7天+关键点  | 时间窗口+事件触发双维度管理 |

### 6.2 核心优势

- LSM-Tree 结构适配写密集型场景：高频写入、顺序写入
- 嵌入式特性减少延迟，提升访问速度
- 数据压缩和存储效率
- 崩溃恢复机制和可靠性，**多版本快照管理**

### 6.3 对比 rocksdb

| **维度**       | **RocksDB**              | **HBase**                         |
| :------------- | :----------------------- | :-------------------------------- |
| **存储模式**   | 嵌入式本地存储（单进程） | 分布式集群存储（多节点协同）      |
| **数据模型**   | 键值存储（Key-Value）    | 列式存储（Column Family）         |
| **写入路径**   | LSM-Tree直接落盘         | 先写HLog→MemStore→定期Flush到HDFS |
| **一致性保证** | 单机ACID                 | 最终一致性（基于ZooKeeper协调）   |
| **访问延迟**   | 微秒级（本地磁盘访问）   | 毫秒级（需网络跳转）              |
| **扩展方式**   | 垂直扩展（单机性能优化） | 水平扩展（增加RegionServer节点）  |

### 6.4  数据模型与架构

- **数据模型**：
    - **表（Table）**：由行（Row）和列（Column）组成。
    - **行键（RowKey）**：唯一标识一行，按字典序排序，设计需避免热点。
    - **列族（Column Family）**：物理存储单元，同一列族的数据存储在同一个HFile中。
    - **时间戳（Timestamp）**：支持多版本数据，按时间倒序排列。
- **架构组件**：
    - **HMaster**：负责元数据管理（表结构、Region分配）、负载均衡。
    - **RegionServer**：管理多个Region，处理读写请求。
    - **Region**：表的分片，按RowKey范围划分，可水平扩展。
    - **ZooKeeper**：协调集群状态（RegionServer存活、元数据存储）

### 6.5 存储与读写流程

- **存储引擎**：
    - 基于LSM树（Log-Structured Merge Tree）：数据先写入内存（MemStore），再合并成HFile持久化到HDFS。
    - 写优化：顺序写、批量合并。
- **读写流程**：
    - **写流程**：Client → ZooKeeper → RegionServer → MemStore（WAL预写日志） → HFile。
    - **读流程**：Client → RegionServer → BlockCache（缓存热数据） → MemStore + HFile合并结果。

### 6.6 核心特性

- **高扩展性**：通过Region分片支持PB级数据。
- **强一致性**：单行事务（ACID）。
- **稀疏存储**：仅存储非空列，适合半结构化数据。
- **多版本控制**：按时间戳保留历史版本数据

### 6.7 性能优化

- **RowKey设计**：
    - 避免热点：散列（Hash前缀）、时间戳反转（如 `reverse(timestamp)`）。
    - 查询模式优先：根据查询需求设计RowKey（如 `用户ID_订单ID`）。
- **预分区（Pre-splitting）**：避免Region自动拆分导致性能波动。
- **缓存机制**：
    - **BlockCache**：缓存HFile数据块（读优化）。
    - **MemStore**：写缓存，定期刷写到HFile。
- **压缩与编码**：使用Snappy或GZIP压缩HFile，减少存储和IO开销

### 6.8 高频问题

- **LSM树的优缺点**：
    - 优点：高吞吐写入，适合写多读少场景。
    - 缺点：读放大（需合并MemStore和多个HFile）。
- **Region分裂过程**：达到阈值（`hbase.hregion.max.filesize`）后分裂为两个子Region。
- **HBase与RDBMS的区别**：无固定Schema、不支持复杂事务、适合海量数据
- HBase的LSM树结构解决了什么问题？写流程是怎样的？
- 如何设计RowKey以避免热点问题？举例说明电商场景中的应用。
- HBase的Region分裂和合并过程是如何触发的？
- HBase如何实现多版本控制？如何清理过期数据？
- HBase与HDFS的关系是什么？为什么HBase不直接替代HDFS？
- 在库存场景中，如何用HBase实现实时更新和历史追溯？
- HBase的Get和Scan操作有什么区别？如何优化Scan性能？
- 什么是协处理器（Coprocessor）？在电商中有哪些应用场景？
- HBase如何保证数据的高可用性？（HDFS副本、Region副本）
- 如何通过Phoenix在HBase上实现SQL查询？

### 6.9 应用

#### 1. **库存管理**

- **实时库存更新**：
    - 利用HBase的高吞吐写入能力，记录库存变更流水（如 `RowKey=商品ID_时间戳`）。
    - 结合Redis缓存实时查询库存（HBase存储全量流水，Redis缓存当前值）。
- **库存历史追溯**：
    - 利用多版本特性，按时间戳查询库存变更记录。
- **热点商品优化**：
    - **RowKey散列**：将热门商品的RowKey添加随机前缀（如 `商品ID % 10_商品ID`），分散到不同Region。

#### **2. 订单与交易流水**

- **海量订单存储**：
    - 设计RowKey为 `用户ID反转_订单时间戳`，支持按用户维度快速查询。
    - 使用列族分离冷热数据（如订单基础信息 vs. 物流详情）。
- **订单状态追踪**：
    - 通过HBase的Get操作快速查询单条订单详情。
    - 利用Filter按条件扫描（如状态为“未支付”的订单）。

#### **3. 用户行为分析**

- **行为日志存储**：
    - 存储用户点击、搜索、购买行为（RowKey=用户ID_行为时间戳）。
    - 结合Phoenix实现SQL化查询（如统计用户活跃度）。
- **实时推荐**：
    - 基于HBase存储用户画像（标签、偏好），实时匹配推荐规则。

#### **4. 供应链数据聚合**

- **分布式统计**：
    - 利用MapReduce或Spark on HBase计算库存周转率、供应商履约率。
    - 通过协处理器（Coprocessor）实现局部聚合，减少网络开销。
- **物流轨迹存储**：
    - 按订单ID+时间戳存储物流节点，支持时间范围查询





熟悉HBase的MemStore刷写机制、Compaction流程。

如何通过预分区、RowKey设计优化性能

HBase与Kafka（实时数据摄入）、Spark（离线分析）的协同使用



## 7、kafka

### 7.1 变更流水核心点

- **顺序保证**：通过Kafka分区键（SKU哈希）保证同一商品顺序性

- **幂等处理**：

    ```java
    // 消费者幂等处理示例
    public void handleMessage(InventoryChange change) {
        if (redis.setnx("change_id:"+change.getChangeId(), "1")) {
            // 实际处理逻辑
            processChange(change);
            redis.expire("change_id:"+change.getChangeId(), 86400);
        }
    }
    ```

- **压缩存储**：

    - 实时流水：Parquet列式存储（Kafka→HDFS）
    - 归档流水：ZSTD压缩+冷存储

### 7.2 架构与核心组件

- **核心角色**：
    - **Broker**：Kafka 服务节点，负责消息存储和转发。
    - **Topic**：消息的逻辑分类（如 `order_events`、`inventory_updates`）。
    - **Partition**：Topic 的物理分片，支持并行读写和水平扩展。
    - **Producer**：消息生产者，按分区策略（Round-Robin、Key Hash）发送消息。
    - **Consumer**：消息消费者，通过消费者组（Consumer Group）实现负载均衡。
    - **ZooKeeper**：管理集群元数据（Broker 状态、Topic 配置）。
- **核心特性**：
    - 高吞吐：顺序磁盘 I/O + 零拷贝（Zero-Copy）技术。
    - 持久化：消息按时间保留（默认 7 天），支持重放。
    - 分布式：Partition 多副本（Replica）机制，Leader-Follower 同步

### 7.3 消息传递语义

**消息可靠性**：

- **At Least Once**（至少一次）：Producer 重试 + Consumer 手动提交 Offset。
- **Exactly Once**（精确一次）：需事务支持（Producer 事务 API）或幂等性设计。
- **At Most Once**（至多一次）：Producer 不重试，Consumer 自动提交 Offset

### 7.4 高可用与容灾

- **副本机制**：
    - Leader 处理读写请求，Follower 异步/同步复制数据。
    - **ISR（In-Sync Replicas）**：与 Leader 保持同步的副本集合。
    - 故障恢复：Leader 宕机时，从 ISR 中选举新 Leader。
- **数据一致性**：
    - **acks 参数**：
        - `acks=0`：不等待确认（可能丢失数据）。
        - `acks=1`：Leader 确认（默认，平衡性能与可靠性）。
        - `acks=all`：所有 ISR 副本确认（最高可靠性）

### 7.5 性能优化

- **分区策略**：
    - 合理分区数：根据吞吐量和消费者并行度设置（避免过多小文件）。
    - 分区键（Key）设计：保证相同 Key 的消息写入同一分区（如订单 ID）。
- **批量与压缩**：
    - 批量发送（`linger.ms` 和 `batch.size`）减少网络开销。
    - 消息压缩（Snappy、GZIP）减少传输数据量。
- **消费者组**：
    - 分区分配策略：Range、Round-Robin、StickyAssignor。
    - 消费者延迟监控：通过 `Consumer Lag` 检测处理滞后

### 7.6 高频问题

- Kafka 为什么吞吐量高？（顺序 I/O、批量处理、零拷贝）
- 如何保证消息顺序性？（单分区内有序，多分区需业务逻辑处理）
- 如何解决重复消费？（幂等性设计、数据库唯一约束）
- 分区数如何影响性能？（分区数过多增加元数据开销）
- Kafka 如何保证消息不丢失？（Producer acks、Broker 副本、Consumer 手动提交）
- 如何实现 Kafka 消息的全局有序？（单分区写入 + 单消费者）
- 消费者组中消费者数量多于分区数会发生什么？（部分消费者闲置）
- 分区 Leader 选举的流程是怎样的？（基于 ZooKeeper 或 KRaft）
- 如何监控 Kafka 集群的健康状态？（JMX 指标、Consumer Lag、Broker 日志）
- 为什么 Kafka 适合日志场景？（高吞吐、持久化、顺序读写）
- 如何解决 Kafka 消费者重复消费？（幂等处理、事务）
- Kafka 与 RabbitMQ 的核心区别是什么？（吞吐量、协议、设计目标）
- 如何设计一个支持百万级 TPS 的 Kafka 集群？（分区规划、硬件优化、副本策略）
- 在电商场景中，如何用 Kafka 实现订单和库存的最终一致性？



### 7.7 应用

#### **订单与交易**

- **订单异步处理**：
    - 用户下单后，订单消息写入 `order_created` Topic，由下游服务异步处理（库存扣减、支付回调、物流通知）。
    - 优势：解耦系统，提高吞吐量。
- **订单状态流转**：
    - 通过多个 Topic（如 `order_paid`、`order_shipped`）实现状态机驱动，保证最终一致性。

#### **2. 库存管理**

- **实时库存更新**：
    - 库存变更（扣减、回滚）通过 `inventory_updates` Topic 广播，多个服务订阅更新（如数据库、缓存）。
    - 示例：用户支付成功后，发送库存扣减消息，确保缓存（Redis）与数据库（MySQL）一致。
- **库存流水溯源**：
    - 所有库存操作记录到 Kafka，供后续对账或审计（如 `inventory_audit` Topic）。

#### **3. 日志与监控**

- **用户行为采集**：
    - 用户点击、搜索、加购行为实时写入 Kafka（如 `user_behavior` Topic），供 Flink/Spark 实时分析。
- **系统监控告警**：
    - 服务日志（如错误日志、性能指标）集中写入 Kafka，对接 ELK 或 Prometheus 实现监控。

#### **4. 流量削峰与错峰处理**

- **秒杀场景**：
    - 瞬时高并发请求写入 Kafka，下游服务按可控速率消费，避免压垮数据库。
    - 示例：用户抢购请求先进入 `seckill_requests` Topic，由库存服务批量处理。
- **批量任务调度**：
    - 定时任务（如每日库存盘点）通过 Kafka 触发，避免集中执行导致资源争抢。

#### **5. 数据一致性保障**

- **跨系统事务**：
    - 通过 Kafka 事务消息实现分布式事务（如扣减库存后发送支付消息，失败则回滚）。
    - 方案：本地事务表 + Kafka 事务 API（两阶段提交）





熟悉 Kafka 的 Log 存储结构、网络模型（Reactor 模式）、ISR 同步机制

如何通过 Kafka 解决高并发、数据一致性等问题