# 一、供应链

## 1、系统总体架构

``` mysql
graph TB
    subgraph 基础设施层
        I1[Kubernetes集群]
        I2[Service Mesh]
        I3[分布式存储]
    end
    
    subgraph 核心服务层
        C1[库存服务] -->|状态同步| C2[仓储服务]
        C2 -->|任务下发| C3[调度服务]
        C3 -->|指令传输| C4[设备控制服务]
        C1 -->|事件发布| C5[消息中心]
    end
    
    subgraph 支撑系统
        S1[监控告警] -->|指标采集| S2[Prometheus]
        S3[日志采集] -->|日志传输| S4[ELK Stack]
        S5[分布式追踪] -->|Span数据| S6[Jaeger]
    end
    
    subgraph 接入层
        A1[API网关] -->|路由| A2[负载均衡]
        A2 -->|服务发现| C1
        A2 -->|服务发现| C2
    end
```

## 2、库存服务

### 2.1 简述

- 架构特性：

    - **单元化部署**：按区域划分库存单元（华北/华东/华南）
    - **读写分离设计**

- 关键技术：

    - **分布式锁**：改进版Redlock实现（增加本地缓存降低Redis压力）

        > 解决高并发下的库存扣减问题，避免超卖，并且保证补货与销售操作的有序性
        >
        > 时钟漂移
        >
        > 通过分桶或分段锁来减少热点商品的竞争

    - **库存快照**：基于RocksDB的本地状态持久化

        > 为了快速恢复或查询历史状态，比如在系统崩溃后恢复数据，或者进行对账

    - **变更流水**：通过CDC(binlog Kafka)同步至数据仓库

        > 追踪库存变化的详细记录，用于审计、对账或补偿操作
        >
        > 监控数据库的binlog，将变更事件发送到Kafka，再由消费者处理到数据仓库或ES
        >
        > 需要强调**顺序性和幂等性**处理，避免重复或丢失数据

### 2.2 库存事务处理

- **分布式事务方案**

    > - **幂等性保障**：通过全局事务ID（txId）实现重复请求过滤
    > - **异步重试**：失败操作进入延迟队列，按指数退避策略重试
    > - **状态跟踪**：Redis存储事务状态机

    ```
    // 库存扣减的Saga模式实现
    public class InventorySaga {
        @SagaStart
        public void deductInventory(Long skuId, Integer count) {
            // Step1: 预占库存
            inventoryService.tempDeduct(skuId, count); 
            
            // Step2: 创建订单
            orderService.createOrder(...);
            
            // Compensation:
            inventoryService.cancelDeduct(skuId, count);
        }
    }
    
    本地库存预扣：提前将库存分配到边缘节点
    异步化扣减：先返回成功再异步持久化
    库存预热：提前加载热点数据到缓存
    ```

- **性能优化**：

    - 热点库存处理：本地缓存+Redis分片+数据库批量合并

        > **本地缓存消峰**(Guava令牌桶实现)
        >
        > **分段锁优化**(将库存拆分为10个分段)
        >
        > **批量合并提交**(合并5ms内的库存变更)

    - 批量操作接口：合并短时间内的多次库存变更

### 2.3 存储架构设计

- **核心存储矩阵**：

    | 数据类型 | 存储方案 | 技术特性          |
    | :------- | :------- | :---------------- |
    | 实时库存 | TiDB集群 | 强一致/HATP       |
    | 操作日志 | Kafka+ES | 顺序写入/快速检索 |
    | 设备状态 | TDengine | 时序数据压缩      |
    | 库存快照 | RocksDB  | 本地持久化        |

- **分库分表策略**：

    ```sql
    -- 库存表分片规则
    CREATE TABLE inventory_${tenant}_${region} (
      sku_id BIGINT,
      warehouse_id INT,
      stock INT,
      PRIMARY KEY(sku_id, warehouse_id)
    ) PARTITION BY HASH(warehouse_id) PARTITIONS 16;
    ```

### 2.4 缓存体系设计

- **三级缓存架构**：

    ```
    本地缓存(Caffeine) → 分布式缓存(Redis) → 持久层(TiDB)
    ```

- **缓存更新策略**：

    ``` java
    // 库存缓存更新示例
    @Cacheable(value = "inventory", key = "#skuId")
    public Inventory getInventory(Long skuId) {
        return dao.get(skuId);
    }
    
    @CacheEvict(value = "inventory", key = "#skuId")
    public void updateInventory(Long skuId) {
        // 更新逻辑
    }
    ```

### 2.5 典型库存操作流程

1. 获取分布式锁（SKU级别）
2. 记录变更预写日志（WAL）
3. 执行数据库更新
4. 生成变更事件（CDC）
5. 释放锁并更新快照
6. 异步处理下游事件

### 2.6 性能优化对比

| 优化前指标      | 优化后指标       | 优化手段                   |
| :-------------- | :--------------- | :------------------------- |
| 锁竞争率：35%   | 锁竞争率：8%     | 分段锁+本地缓存优化        |
| 快照延迟：15秒  | 快照延迟：3秒    | 内存表分片+并行持久化      |
| 流水处理TPS：5K | 流水处理TPS：50K | Kafka批量压缩+消费者组优化 |
| 恢复时间：5分钟 | 恢复时间：30秒   | 快照预热+增量日志回放      |

## 3、仓储调度服务

**架构设计**：

- 任务队列分级：

    | 队列等级 | 响应要求 | 典型场景 |
    | :------- | :------- | :------- |
    | L0       | <100ms   | 紧急补货 |
    | L1       | <1s      | 常规补货 |
    | L2       | <5s      | 库存盘点 |

- 设备通信协议栈：

    ``` 
    TCP长连接 → Protobuf协议编解码 → 指令优先级队列 → 应答确认机制
    ```

## 4、前置仓管理系统

### 4.1 简述

- **核心组件**：
    - 容量监控服务：实时计算仓容水位
    - 温控监管服务：对接IoT设备数据流
    - 动态路由服务：与配送系统实时联动
- **数据同步机制**：
    - 前置仓终端->>边缘计算节点: 上报库存变更
    - 边缘计算节点->>区域中心: 批量同步数据(每5s)
    - 区域中心->>中央库存服务: 最终一致性同步
    - 中央库存服务-->>前置仓终端: 反向配置更新

### 4.2 服务治理体系

- **核心能力矩阵**：

    | 治理维度 | 技术方案         | 关键指标         |
    | :------- | :--------------- | :--------------- |
    | 流量控制 | Sentinel集群流控 | QPS阈值/异常比例 |
    | 服务容错 | Resilience4j熔断 | 失败率阈值       |
    | 灰度发布 | Istio流量染色    | 版本分流比例     |
    | 异常隔离 | Hystrix舱壁模式  | 线程池隔离度     |

- **服务网格集成**：

    ```
    # Istio VirtualService配置示例
    apiVersion: networking.istio.io/v1alpha3
    kind: VirtualService
    metadata:
      name: inventory-vs
    spec:
      hosts:
      - inventory-service
      http:
      - route:
        - destination:
            host: inventory-service
            subset: v1
        mirror:
          host: inventory-service
          subset: v2
        retries:
          attempts: 3
          retryOn: 5xx
    ```

# 二、基础

## 1、spring

### 1.1 Bean 的作用域

- `singleton`：默认，每个容器中只有一个 bean 实例，由 BeanFactory 自身来维护
- `prototype`：为每一个 bean 请求提供一个实例
- `request`：为每一个网络请求创建一个实例，在请求完成以后，bean 会失效并被垃圾回收器回收
- `session`：与request范围类似，确保每个 session 有一个 bean 实例，session 过期后，bean 会随之失效
- `global-session`：全局作用域，与 Portlet 应用相关，所有 Portlet 可以共用存储在 global-session 中的全局变量，全局作用域与Servlet中的session作用域效果相同

### 1.2 Bean 创建与循环依赖

- Bean 的创建流程：
  - `createBeanInstance`：实例化，即调用对象的构造方法实例化对象
  - `populateBean`：填充属性，主要是对 bean 的依赖属性进行填充

  - `initializeBean`：调用 spring xml 中的 init 方法

- 解决单例的循环依赖问题，使用了**三级缓存**： 

  - 三级缓存 `singletonFactories`： 单例对象工厂的 cache 

    > 解决循环依赖的诀窍是 singletonFactories，这个cache的类型是 ObjectFactory

  - 二级缓存 `earlySingletonObjects`：提前曝光的单例对象的 cache 

  - 一级缓存 `singletonObjects`：单例对象的 cache

三级缓存流程： A 的某个 field 或 setter 依赖 B 的实例对象，同时 B 的某个 field 或 setter 依赖 A 的实例对象： 

> 1. A 首先完成初始化的第一步，将自己提前曝光到 singletonFactories 中
>
> 2. 进行初始化的第二步时，发现自己依赖对象 B，此时尝试 get(B)，发现 B 还未 create，所以走 create B 流程
>
> 3. B 在初始化第一步时，发现依赖对象 A，于是尝试 get(A)，尝试一级缓存 singletonObjects，二级缓存 earlySingletonObjects 都没有，在三级缓存 singletonFactories 中拿到
>
>    > 由于 A 通过 ObjectFactory 将自己提前曝光，所以 B 能够通过 ObjectFactory.getObject 拿到 A 对象
>
> 4. B 拿到 A 对象后顺利完成了初始化阶段 1、2、3，完全初始化之后将自己放入到一级缓存
>
> 5. B 创建完成后返回 A 中，A 此时能拿到 B 的对象顺利完成自己的初始化阶段2、3，并放入一级缓存 singletonObjects 中
>
>    > 更加幸运的是，由于 B 拿到了 A 的对象引用，所以 B 现在 hold 住的 A 对象完成了初始化
>
> **加入 singletonFactories 三级缓存的前提是执行了构造器**，所以**构造器的循环依赖没法解决**

### 1.3 事务管理

- **事务管理**： 用来确保数据的完整性和一致性

  - **原子性(atomicity)**：事务的原子性确保动作要么全部完成，要么完全不起作用
  - **一致性(consistency)**: 一旦所有事务动作完成，事务就被提交
  - **隔离性(isolation)**: 每个事物都应与其他事务隔离开来，防止处理相同数据时导致数据损坏
  - **持久性(durability)**:  事务的结果被写到持久化存储器中

- **并发事务所导致的问题**： 

  - **脏读**： 对于两个事物 T1、T2，T1  读取了已经被 T2 更新但还没有被提交的字段后，若 T2 回滚，T1读取的内容就是临时且无效
  - **修改丢失**： 对于两个事物 T1、T2，T1  修改了一个字段，同时 T2 也修改了该字段，则 T1 修改的结果丢失
  - **不可重复读**： 对于两个事物 T1、T2，T1  读取了一个字段，然后 T2 更新了该字段后，T1再次读取同一个字段，值发生变化
  - **幻读**： 对于两个事物 T1、T2，T1  从一个表中读取了一个字段，然后 T2 在该表中插入了一些新的行后，如果 T1 再次读取同一个表，就会多出几行

- **五个隔离级别**：

  - `TransactionDefinition.ISOLATION_DEFAULT`： 使用底层数据库的默认隔离级别

    > Mysql 默认采用的 `REPEATABLE_READ` 隔离级别
    >
    > Oracle 默认采用的 `READ_COMMITTED` 隔离级别

  - `TransactionDefinition.ISOLATION_READ_UNCOMMITTED`： 最低隔离级别(默认)，允许读取尚未提交的数据变更

    > 可能会导致脏读、幻读或不可重复读

  - `TransactionDefinition.ISOLATION_READ_COMMITTED`： 允许读取并发事务已经提交的数据

    > 可以阻止脏读，但幻读或不可重复读仍可能发生

  - `TransactionDefinition.ISOLATION_REPEATABLE_READ`： 确保事务可以多次从一个字段中读取相同的值，在事务持续期间，禁止其他事务对这个字段进行更新

    > 可以阻止脏读和不可重复读，但幻读仍可能发生

  - `TransactionDefinition.ISOLATION_SERIALIZABLE`： 确保事务可以从一个表中读取相同的行，在这个事务持续期间，禁止其他事务对该表执行插入、更新、删除操作，所有并发问题都可以避免，但性能低下

- **事务传播机制**：
  - **支持当前事务的情况**： 
    - `TransactionDefinition.PROPAGATION_REQUIRED`： 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务
    - `TransactionDefinition.PROPAGATION_SUPPORTS`： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行
    - `TransactionDefinition.PROPAGATION_MANDATORY`： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常(mandatory：强制性)
  - **不支持当前事务的情况**： 
    - `TransactionDefinition.PROPAGATION_REQUIRES_NEW`： 创建一个新的事务，如果当前存在事务，则把当前事务挂起
    - `TransactionDefinition.PROPAGATION_NOT_SUPPORTED`： 以非事务方式运行，如果当前存在事务，则把当前事务挂起
    - `TransactionDefinition.PROPAGATION_NEVER`： 以非事务方式运行，如果当前存在事务，则抛出异常
  - **其他情况：**
    - `TransactionDefinition.PROPAGATION_NESTED`： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则等价于 TransactionDefinition.PROPAGATION_REQUIRED

- **事务超时**： 指一个事务所允许执行的最长时间，如果超过该时间限制但事务还没有完成，则自动回滚事务

- **事务只读属性**： 指对事务性资源进行只读操作或读写操作

- **回滚规则**： 定义哪些异常会导致事务回滚而哪些不会

  > - 默认情况下，只有未检查异常(`RuntimeException和Error`类型的异常)会导致事务回滚
  > - @Transactional 注解的 `rollbackFor 和 noRollbackFor` 属性定义回滚类型
  > - xml 文件中，可以在 `<tx:method>` 元素中指定回滚规则，可用用逗号分隔多个规则

- **@Transactional 注解属性详解**： 

  - `propagation`： 指定事务的传播行为，即当前的事务方法被另外一个事务方法调用时如何使用事务

    > 默认取值为 REQUIRED，即使用调用方法的事务

  - `isolation`： 指定事务的隔离级别，最常用的取值为 `READ_COMMITTED`

  - `noRollbackFor`： 设置异常是否回滚，默认情况下 Spring 的声明式事务对所有的运行时异常进行回滚

  - `readOnly`： 指定事务是否为只读，表示这个事务只读取数据但不更新数据

  - `timeout`： 指定强制回滚之前事务可以占用的时间

### 1.4 设计模式应用

- **工厂设计模式**： Spring 使用工厂模式通过 `BeanFactory`、`ApplicationContext` 创建 bean 对象
- **代理设计模式**： Spring AOP 功能的实现
- **单例设计模式**： Spring 中的 Bean 默认都是单例
- **模板方法模式**： Spring 中 `jdbcTemplate`、`hibernateTemplate` 等以 Template 结尾的对数据库操作的类
- **包装器设计模式**： 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源
- **观察者模式**： Spring 事件驱动模型就是观察者模式很经典的一个应用
- **适配器模式**： Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配 `Controller` 

## 2、mybatis

### 2.1 核心组件

- `SqlSessionFactory`：全局单例，用于创建 `SqlSession`。
- `SqlSession`：执行SQL、管理事务的会话（线程不安全，需每次请求创建）。
- `Mapper` 接口：通过动态代理绑定到XML或注解的SQL。
- `Executor`：SQL执行器（Simple、Reuse、Batch）

### 2.2 SQL 映射与动态 SQL

1. **参数与结果映射**

    - `#{}` 和 `${}` 的区别：预编译（防SQL注入） vs. 字符串替换

        > 如何防止 SQL 注入？

    - `@Param` 注解的作用：多参数映射。

    - `resultMap`：自定义结果集映射（处理复杂对象、关联查询）

        > `<resultMap>` 的作用是什么？如何映射复杂对象（如嵌套对象）？

1. **动态 SQL 标签**
    - `<if>`、`<choose>/<when>/<otherwise>`：条件分支
    - `<foreach>`：遍历集合（IN查询、批量插入）
    - `<where>`、`<set>`、`<trim>`：智能处理SQL片段

### 2.3 缓存机制

1. **一级缓存（本地缓存）**
    - 默认开启，`SqlSession` 级别，执行`commit`、`close`或`clearCache`后失效
    - 问题：重复查询可能命中缓存，导致脏读（需注意作用域）

2. **二级缓存（全局缓存）**

    > 二级缓存开启后，同一个 namespace 下的所有 SQL 语句都是共用同一个 Cache，即二级缓存被多个 SqlSession 共享

    - `Mapper` 级别，需手动配置（`<cache>`标签或`@CacheNamespace`）
    - 缓存策略：LRU、FIFO、SOFT/WEAK（内存敏感场景）
    - 注意事项：序列化、事务提交后才生效、多表关联可能脏读

#### 2.4 与 Spring 集成

1. **MyBatis-Spring 整合**
    - 配置方式：`SqlSessionFactoryBean`、`MapperScannerConfigurer`。
    - `SqlSessionTemplate`：线程安全的`SqlSession`封装。
    - 事务管理：由Spring的`DataSourceTransactionManager`控制。
2. **Mapper 接口原理**
    - 动态代理：通过`MapperProxy`将接口方法绑定到XML或注解SQL。
    - `@MapperScan`：自动扫描并注册Mapper接口

### 2.5 分页实现

- **物理分页**：数据库方言（如MySQL的`LIMIT`）

  > - **优点**：直接由数据库处理，性能较高。
  > - **缺点**：`OFFSET` 过大时性能下降（需扫描大量数据）
  > - 优化：使用游标分页

  ```sql
  SELECT * FROM table LIMIT 10 OFFSET 20; -- 第3页（每页10条）
  ```

- **逻辑分页**：`RowBounds`（内存分页，不推荐大数据量）

  > 一次性查询所有数据，在应用层（如 Java）进行分页

- **游标分页**：使用索引列（如自增ID）作为游标，避免 `OFFSET`

  > - 优点：高性能，适合大数据量
  > - 缺点：仅支持顺序翻页，不能跳页

  ```sql
  SELECT * FROM table WHERE id > last_id ORDER BY id LIMIT 10;
  ```

---

**PageHelper(自动改写SQL)**：

- **实现**：通过拦截器动态修改 SQL 实现分页

- **原理**：将分页参数（页码、每页条数）存入 `ThreadLocal`，确保线程安全

- 改写：

  ```sql
  原始SQL --> SELECT * FROM table WHERE condition;
  改写后 --> SELECT * FROM table WHERE condition LIMIT pageSize OFFSET offset;
  ```

### 2.8 批量插入

如何优化 MyBatis 的批量插入性能？

- 批量插入性能问题：

  - **逐条插入**：每条 INSERT 语句单独提交，网络 I/O 和事务开销极大。
  - **内存溢出**：一次性加载过多数据到内存。
  - **未启用批处理**：未正确利用 JDBC 的批处理能力

- **使用 `foreach` 标签合并单条 SQL（适合小批量）**：

  - **原理**：将多条 INSERT 合并为一条 SQL，减少网络交互次数。
  - **缺点**：
    - SQL 长度可能超出数据库限制（如 MySQL 的 `max_allowed_packet`）。
    - 不适合超大数据量（如 10 万条以上）

- **使用 `ExecutorType.BATCH` + JDBC 批处理（推荐大批量）**：

  - **原理**：通过 MyBatis 的批量执行器，利用 JDBC 的 `addBatch()` 机制

  ```java
  // 获取批量模式的 SqlSession
  SqlSession sqlSession = sqlSessionFactory.openSession(ExecutorType.BATCH);
  UserMapper mapper = sqlSession.getMapper(UserMapper.class);
  
  try {
      for (int i = 0; i < list.size(); i++) {
          mapper.insert(list.get(i));
          if (i % 1000 == 0 || i == list.size() - 1) {
              sqlSession.flushStatements(); // 刷入批处理
              sqlSession.clearCache();       // 清空缓存防止内存溢出
          }
      }
      sqlSession.commit(); // 统一提交事务
  } finally {
      sqlSession.close();
  }
  ```

### 2.9 N+1 问题

- **N+1 查询问题**：指通过一次主查询（1次）获取 N 条主数据后，再通过额外的 N 次子查询获取关联数据

- **如何解决**：

  - **JOIN 查询 + 手动映射（推荐）**：通过单次 JOIN 查询一次性获取主数据和关联数据，利用 MyBatis 的 ResultMap 手动映射结果

    > - **优点**：查询次数降为 1 次，性能最优。
    > - **缺点**：JOIN 可能导致结果集膨胀（重复主数据），需手动去重

  - **批量查询（Batch Query）**：先查询主数据，收集所有主键，再通过一次子查询获取所有关联数据，最后在代码层组装

    > - **优点**：总查询次数降为 2 次，适合主数据量大的场景。
    > - **缺点**：需手动处理数据组装逻辑

  - **启用懒加载（Lazy Loading）**：延迟加载关联数据，仅在访问关联属性时触发查询

    > ```xml
    > <collection 
    >   property="items" 
    >   column="id" 
    >   ofType="OrderItem"
    >   select="selectOrderItemsByOrderId"
    >   fetchType="lazy"/> <!-- 标记为懒加载 -->
    > ```
    >
    > - **优点**：避免一次性加载所有关联数据。
    > - **缺点**：
    >   - 若遍历所有主数据并访问关联属性，仍会触发 N+1 查询。
    >   - 需确保 Session 生命周期管理（如使用 Open Session In View 模式）

## 3、设计模式





## 4、mysql

### 4.1 索引

B+ 树：

> 相对于跳表，减少寻址次数

- 单一节点存储更多的元素，使得查询的IO次数更少
- 所有查询都要查找到叶子节点，查询性能稳定
- 所有叶子节点形成有序链表，便于范围查询

![](../pics/mysql/global/mysql_1.png)

- **聚簇索引**：索引的叶子节点直接存储完整的行数据

  - **物理有序**：数据按聚簇索引键值的顺序存储，因此主键范围查询效率高

- **非聚簇索引**：索引的叶子节点存储的是**主键值（而非数据行）+ 索引列**

  - 回表查询：**先遍历辅助索引查找到主键值，再通过主键索引找到完整的行记录** 

    > 原理：当查询的列未完全包含在非聚簇索引中时，需通过主键值回到聚簇索引中检索完整数据行
    > 解决：设计索引时，让索引包含查询需要的所有列，避免回表

- 索引优化：
  - 覆盖索引：即非聚簇索引包含查询需要的所有列，避免回表
  - 最左前缀原则：索引字段顺序指定，避免跳过索引字段

- **检测 sql**：通过 `EXPLAIN` 分析执行计划，关注 `rows`、`key`、`type`，避免全表扫描

### 4.2 锁

- 行锁模式：
  - **共享锁（S Lock）**：允许其他事务读，阻塞写（`SELECT ... LOCK IN SHARE MODE`）
  - **排他锁（X Lock）**：禁止其他事务读写（`SELECT ... FOR UPDATE`、DML 语句）

- 行锁类型：
  - **记录锁(Record Lock)**：锁定索引中的一条记录
  - **间隙锁(Gap Lock)**：锁定索引记录之间的间隙（防止幻读），仅存在于 **可重复读（RR）** 隔离级别
  - **临键锁(Next-Key Lock)**：记录锁 + 间隙锁，锁定左开右闭区间（如 `(5, 10]`），解决幻读问题（RR 隔离级别默认）

- 意向锁（Intention Lock）：
  - **意向共享锁（IS）**：事务准备对某些行加 S 锁
  - **意向排他锁（IX）**：事务准备对某些行加 X 锁

- 死锁检测与处理：
  - **自动检测**：InnoDB 使用等待图（Wait-For Graph）检测死锁
  - **解决方案**：强制回滚代价较小的事务（通过 `SHOW ENGINE INNODB STATUS` 查看死锁日志）

| **隔离级别**         | **脏读** | **不可重复读** | **幻读** | **锁机制**                    |
| :------------------- | :------- | :------------- | :------- | :---------------------------- |
| **读未提交（RU）**   | 可能     | 可能           | 可能     | 不加锁（通过 MVCC 实现）      |
| **读已提交（RC）**   | 不可能   | 可能           | 可能     | 仅加记录锁，无间隙锁          |
| **可重复读（RR）**   | 不可能   | 不可能         | 可能     | 记录锁 + 间隙锁（默认防幻读） |
| **串行化（Serial）** | 不可能   | 不可能         | 不可能   | 强制加锁，最高隔离            |

### 4.3 事务

- 事务**并发问题**如何发生： 当多个事务同时操作同一个数据库的相同数据时

  - **脏读**：一个事务读取到了另外一个事务未提交的数据

  - **不可重复读**：同一个事务中，多次读取到的数据不一致

  - **幻读**：一个事务读取数据时，另外一个事务进行更新，导致第一个事务读取到了没有更新的数据


- 四个隔离级别为：

  - `READ UNCOMMITTED`(读未提交)： **称为浏览访问，仅仅针对事务而言**

    > 允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读** 


  - `READ COMMITTED`(读已提交)： **称为游标稳定**，避免脏读，但导致不可重复读

    > 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍可能发生** 


  - `REPEATABLE READ`(可重复读)： **是 2.9999° 的隔离，没有幻读的保护**，避免不可重复读

    > 对同一字段的多次读取结果一致，**可以阻止脏读和不可重复读，但幻读仍可能发生** 


  - `SERIALIZABLE`(序列化)： **称为隔离或 3° 的隔离 ** 

    > 所有事务依次执行，事务之间不会产生干扰，**该级别可以防止脏读、不可重复读以及幻读** 

### 4.4 MVCC

通过保存数据的多个版本来实现高并发读写，同时保证事务的隔离性

> 是 InnoDB 引擎实现 **可重复读（RR）** 和 **读已提交（RC）** 隔离级别的核心机制

- **数据多版本**：每条记录的每次修改都会生成一个版本链，旧版本数据存储在 **Undo Log** 中

  > **Undo Log**：
  >
  > - 支持事务回滚
  > - 支持 MVCC 读取历史快照

- **快照读（Snapshot Read）**：事务读取数据时，基于某个时间点的快照版本，而非实时数据

- **版本链访问**：当查询数据时，InnoDB 会根据当前事务的 ReadView，沿版本链找到符合可见性条件的记录

- **不同隔离级别的 MVCC 表现**：

  - **读已提交**：每次执行 SELECT 语句时生成新的 ReadView

    > - 能读到其他事务已提交的最新数据。
    > - 可能出现不可重复读（同一事务两次查询结果不一致）

  - **可重复读**：事务第一次 SELECT 时生成，后续复用同一个 ReadView

    > - 保证同一事务内多次查询结果一致（避免不可重复读）
    > - 通过 **间隙锁（Gap Lock）** 避免幻读（当前读），但快照读（普通 SELECT）仍可能因版本链覆盖而出现幻读

| **问题**       | **解决方式**                                                 |
| :------------- | :----------------------------------------------------------- |
| **脏读**       | 只读取已提交事务的版本（通过 ReadView 过滤未提交事务的修改） |
| **不可重复读** | 在 RR 级别下，复用同一个 ReadView，保证事务内看到一致的数据快照 |
| **幻读**       | 快照读通过 MVCC 避免幻读；当前读（如 `SELECT ... FOR UPDATE`）通过间隙锁解决 |

### 4.5 Binlog、Redo Log、Undo Log

| 特性         | Binlog (二进制日志)       | Redo Log (重做日志)          | Undo Log (回滚日志)         |
| :----------- | :------------------------ | :--------------------------- | :-------------------------- |
| **所属层级** | MySQL Server层            | InnoDB存储引擎层             | InnoDB存储引擎层            |
| **日志类型** | 逻辑日志（SQL语句）       | 物理日志（页级修改）         | 逻辑日志（行记录前镜像）    |
| **主要用途** | 主从复制、数据恢复        | 崩溃恢复                     | 事务回滚、MVCC              |
| **写入时机** | 事务提交后                | 事务执行过程中               | 数据修改前                  |
| **生命周期** | 可配置保留时间            | 循环覆盖写入                 | 随事务结束可清理            |
| **文件形式** | 独立文件（binlog.000001） | 固定大小文件组（ib_logfile） | 存储在系统表空间/undo表空间 |

### 4.6 主从复制与读写分离

- **主从复制**：

    - **基本概念**

      - **主库（Master）**：处理所有写操作（INSERT/UPDATE/DELETE），并将数据变更记录到二进制日志（Binary Log）

      - **从库（Slave）**：从主库同步二进制日志，并在本地重放这些操作，实现数据复制。从库通常用于读操作（SELECT）

    - **从库同步流程**
      - **I/O线程**：从库通过I/O线程连接到主库，读取主库的二进制日志并保存为中继日志（Relay Log）。
      - **SQL线程**：从库的SQL线程读取中继日志中的事件，并在本地重放这些操作，实现数据同步
    - 复制方式：
      - **异步复制(默认)**：主库提交事务后无需等待从库确认，性能高但存在短暂数据不一致风险
      - **半同步复制(保证数据一致性)**：主库提交事务时，至少等待**一个从库确认收到 Binlog 事件**后才返回成功给客户端
      - **GTID + 一致性读**：
        - 使用全局事务标识（GTID）跟踪事务，确保从库应用完特定事务后再读取
        - 客户端记录主库的 GTID，查询从库时等待其同步到该 GTID

- **读写分离**：

    - **核心思想**

      - **写操作**：仅由主库处理（INSERT/UPDATE/DELETE）

      - **读操作**：分发到从库或多个从库（SELECT）

    - **应用层控制**：数据库中间件（如MyCat、ProxySQL、MaxScale）自动路由请求

      - 写请求：连接主库
      - 读请求：轮询或随机选择从库

### 4.7 分库分表

- **分库分表的核心思想**

  - **垂直拆分**：按业务模块或字段拆分表或库（如订单库、用户库）

  - **水平拆分**：将单表数据按规则（如哈希、范围）分散到多个库或表中

- **分库分表的挑战**

  - **跨库查询**：JOIN、排序、分页需合并结果（ShardingSphere 支持有限）

  - **分布式事务**：使用 Seata、XA 协议或最终一致性补偿

  - **扩容**：数据迁移复杂，推荐初期预留分片或使用一致性哈希

- 分库分表后如何实现全局唯一ID？（雪花算法、Redis自增）

> **旧数据归档**：将历史数据迁移到归档表或归档库

---

分库分表后，如何实现跨分片的排序和分页？

- **全局表/索引方案**：维护额外的全局表
- **内存排序方案**：从所有分片查询满足条件的数据，在应用内存中进行合并、排序

- **二次查询方案**：第一次查询只获取排序字段和主键，在内存中排序并确定最终需要的主键，第二次查询根据主键获取完整数据

---

订单表数据量过大，如何设计分表策略？

- **按时间维度分表（推荐）**：订单有明显的时间特征，查询常按时间范围筛选
- **按用户ID哈希分表**：用户维度查询频繁
- **按订单ID范围分表**：ID自增且查询多按ID范围

### 4.8 应用

- **扣减一致性**：

    - **超卖问题**：通过事务+行锁（`SELECT ... FOR UPDATE`）或乐观锁（版本号）保证原子性。
    - **预扣库存**：下单时预扣库存，支付成功后实际扣减，超时未支付回滚。

    > 电商场景中，如何解决超卖问题？除了锁还有什么方案？

- **热点行优化**：

    - **批量扣减**：将单行库存拆分为多行（如库存分桶），减少锁竞争。
    - **异步队列**：通过消息队列（如 Kafka）削峰，异步处理库存更新。

- **高频问题**：

    - 如何设计一个支持高并发秒杀的库存系统？
    - 分桶库存的实现原理是什么？

- **事务一致性**：
    - 订单创建需保证：扣库存、生成订单、记录流水的事务原子性。
    - 最终一致性方案：TCC（Try-Confirm-Cancel）、本地消息表。
- **数据分片**：
    - 订单表按用户ID分片，避免单表过大。
    - 历史订单归档：按时间分区，冷热数据分离。
- **高频问题**：
    - 如何处理订单支付超时？（定时任务扫描+状态回滚）

- **复杂查询优化**：
    - 多表关联查询（订单、物流、库存）使用覆盖索引或冗余字段。
    - 聚合查询（如库存周转率）使用物化视图或预计算。
- **数据一致性**：
    - 分布式事务：跨库存、物流系统的数据同步（如基于 Binlog 的 CDC 技术）。
- **高频问题**：
    - 如何实时监控库存周转率？（定时任务+聚合表）

- **缓存结合**：
    - 读多写少场景（如商品详情）使用 Redis 缓存，缓存击穿/穿透/雪崩解决方案。
    - 库存缓存：Redis 预扣库存，异步同步到数据库。
- **容灾备份**：
    - 主从切换（Keepalived）、跨机房容灾（双活架构）。
    - 数据备份：全量备份（mysqldump）+ Binlog 增量恢复。

## 5、redis

### 5.1 分布式锁(redLock)

> 用于在分布式环境下实现跨多个 Redis 节点的互斥锁

RedLock 算法核心思想是：**在大多数 Redis 节点上获取锁**，而不是依赖单个 Redis 实例。基本步骤如下：

1. 获取当前时间（毫秒精度）
2. 依次尝试从 N 个独立的 Redis 实例获取锁
3. 计算获取锁花费的总时间（当前时间 - 步骤1的时间）
4. 如果满足以下条件则认为获取锁成功：
   - 从大多数（N/2 + 1）节点获取到了锁
   - 总耗时小于锁的过期时间

注意点：

1. **时钟同步问题**：RedLock 依赖于系统时钟的正确性。如果某些 Redis 节点的时钟不同步，可能会导致锁提前过期或被错误持有
2. **锁续期**：对于长时间操作，需要考虑实现锁续期机制（watchdog）
3. **性能考虑**：由于需要与多个 Redis 节点通信，RedLock 的性能比单节点锁要低
4. **网络分区**：在网络分区情况下，可能会出现多个客户端同时持有锁的情况

```java
// 改进版Redlock实现（Java示例）
public class InventoryLock {
    private static final String LOCK_PREFIX = "lock:sku:";
    private static final int LOCK_EXPIRE = 3000; // 3秒
    
    public boolean tryLock(String skuId, String requestId) {
        String key = LOCK_PREFIX + skuId;
        return redisTemplate.execute((RedisCallback<Boolean>) conn -> {
            // 使用Lua脚本保证原子性
            String luaScript = 
                "if redis.call('setnx', KEYS[1], ARGV[1]) == 1 then " +
                "   redis.call('pexpire', KEYS[1], ARGV[2]); " +
                "   return 1; " +
                "else " +
                "   return 0; " +
                "end";
            Object result = conn.eval(
                luaScript.getBytes(), 
                ReturnType.INTEGER, 
                1, 
                key.getBytes(), 
                requestId.getBytes(), 
                String.valueOf(LOCK_EXPIRE).getBytes()
            );
            return (Long)result == 1;
        });
    }
}
```

**多级锁优化策略**

```
graph TD
    A[请求进入] --> B{本地锁竞争}
    B -->|成功| C[Redis集群锁]
    B -->|失败| D[快速失败返回]
    C -->|成功| E[执行库存操作]
    C -->|失败| F[进入等待队列]
```

**工程实践要点**

- **锁粒度优化**：采用分段锁（如将SKU_1001拆分为SKU_1001_01~SKU_1001_10）
- **锁续期机制**：后台线程自动延长锁有效期
- **故障转移**：通过ZooKeeper实现锁服务高可用

### 5.2 ThreadLocal 与 Caffeine

- **`ThreadLocal`**：

  - **数据结构**

    - 每个线程（`Thread` 类）内部维护一个 `ThreadLocalMap`，其键为 `ThreadLocal` 实例，值为线程局部变量
    - `ThreadLocalMap` 的 `Entry` 使用**弱引用（`WeakReference`）**包装 `ThreadLocal` 实例，避免内存泄漏

    > 强引用：可以直接访问目标对象，垃圾收集器不会回收掉强引用对象
    >
    > 软引用：在内存不够时会被回收
    >
    > **弱引用**：只能存活到下一次垃圾回收发生前
    >
    > 虚引用：对象是否有虚引用，不会对其生存时间构成影响，也无法通过虚引用取得一个对象

  - **变量隔离机制**

    - 当调用 `ThreadLocal.set(value)` 时，数据存储在当前线程的 `ThreadLocalMap` 中
    - 调用 `ThreadLocal.get()` 时，从当前线程的 `ThreadLocalMap` 中取出与当前 `ThreadLocal` 关联的值

  - **哈希冲突处理**

    - `ThreadLocalMap` 使用线性探测法（而非链地址法）解决哈希冲突，通过顺序查找下一个空槽

  - **内存泄漏问题**：

    - **根源**
      - `ThreadLocalMap` 的键（`ThreadLocal` 实例）是弱引用，但值是强引用
      - 若 `ThreadLocal` 实例被回收，但 `ThreadLocalMap` 中值的强引用未被清除，会导致 Entry 无法回收
    - **解决方案**
      - **及时调用 `remove()`**：在使用完毕后（尤其是线程池场景），必须调用 `remove()` 清理数据
      - **避免长生命周期线程**：线程池中的线程可能长期存活，需确保每次任务结束后清理 `ThreadLocal`

- **`Caffeine`**：

  - **缓存淘汰策略**：Window-TinyLFU 算法，其核心思想：

    - **LRU（最近最少使用）**：维护一个“最近使用”队列

    - **TinyLFU（频率统计）**：通过 Count-Min Sketch 算法统计数据的访问频率

    - **窗口缓存（Window Cache）**：新数据先进入窗口缓存区，高频访问的数据晋升到主缓存区

  - **并发优化**

    - **无锁读操作**：读操作完全无锁，依赖 `ConcurrentHashMap` 实现高并发读

    - **分段写锁**：写操作采用分段锁（类似 `ConcurrentHashMap`），减少锁竞争

    - **缓冲队列**：将并发写入操作缓冲到队列中，批量合并处理，减少锁冲突

  - **内存管理**

    - **权重控制**：支持按条目数或内存权重（如对象大小）限制缓存容量

    - **弱引用/软引用**：允许缓存键或值使用弱引用或软引用，避免内存溢出

    - **自动过期**：支持基于时间（访问后、写入后）或自定义策略的自动过期

### 5.3 数据结构与适用场景

- **String**：缓存、计数器（库存预扣）、分布式锁。
- **Hash**：存储对象（用户信息、商品详情）。
- **List**：消息队列、最新消息排行（如订单流水）。
- **Set**：唯一性集合（抽奖去重、共同好友）。
- **ZSet**：排行榜（商品销量、用户积分）。
- **BitMap**：签到统计、用户行为标记。
- **HyperLogLog**：UV 统计（近似去重计数）。
- **Stream**：消息队列（替代 List，支持多消费者组）

### 5.4 持久化机制

- **RDB（快照）**：
    - 定时生成数据快照，适合备份恢复。
    - 缺点：可能丢失最后一次快照后的数据。
- **AOF（追加日志）**：
    - 记录写操作命令，数据丢失风险低。
    - 重写机制（Rewrite）压缩日志文件。

### 5.5 主从复制

主从复制是**异步复制**机制，主节点（Master）处理写操作后，通过异步方式将数据变更同步到从节点（Slave）

- **主从不一致解决**：
  - **强制读主**：在写操作后的关键时间窗口内（如 1s），强制后续读请求访问主节点。
  - **使用 `WAIT` 命令（同步复制）**：确保写操作在多个从节点持久化，实现**强一致性**
  - **优化主从复制性能**：增大主节点复制缓冲区、控制主节点写入速率、硬件及网络优化
  - **最终一致性补偿**：
    - **异步校验**：定期对比主从数据（如使用 `SCAN` 遍历键）
    - **消息队列补偿**：写操作同时发送消息到队列，从节点消费消息后二次校验数据

| **方案**       | **一致性强度** | **延迟影响**   | **实现复杂度** | **适用场景**                     |
| :------------- | :------------- | :------------- | :------------- | :------------------------------- |
| 强制读主       | 强一致性       | 增加主节点负载 | 低             | 金融交易、库存扣减               |
| `WAIT` 命令    | 强一致性       | 高延迟         | 中             | 极小规模集群、关键配置更新       |
| 监控告警       | 最终一致性     | 无影响         | 高             | 配合运维体系使用                 |
| 优化主从性能   | 降低延迟概率   | 无影响         | 中             | 所有主从架构通用                 |
| 最终一致性补偿 | 最终一致性     | 低延迟         | 高             | 对一致性要求宽松的场景（如缓存） |

### 5.6 性能与内存管理

- **内存淘汰策略**：
    - `volatile-lru`（最近最少使用）、`allkeys-lfu`（最不经常使用）等。
- **缓存穿透**：恶意查询不存在的数据。
    - 解决方案：布隆过滤器（Bloom Filter）、空值缓存。
- **缓存击穿**：热点数据过期后高并发请求穿透到数据库。
    - 解决方案：互斥锁（SETNX）、永不过期 + 异步更新。
- **缓存雪崩**：大量数据同时过期导致请求打到数据库。
    - 解决方案：随机过期时间、多级缓存（Redis + 本地缓存）

### 5.7  Redis 实现延迟队列

- 基于 **有序集合（Sorted Set）** 的延迟队列：将任务的到期时间作为分数（score），任务内容作为成员（member），通过轮询有序集合中到期的任务实现延迟消费

  > - **添加延迟任务**：将任务按执行时间戳（延迟时间 + 当前时间）存入 Sorted Set
  > - **轮询到期任务**：消费者定期查询当前时间之前的所有任务
  > - **处理任务**：消费者遍历获取的任务列表，执行业务逻辑

- 基于 **过期事件监听（Key Notifications）** 的延迟队列：利用 Redis 的键过期事件（`expired`），将任务 ID 设为键，过期时间作为延迟时间，过期时触发事件，将任务推入处理队列

  > - **启用 Redis 键空间通知**：修改 Redis 配置，开启过期事件监听
  > - **添加延迟任务**：将任务 ID 设为键，设置过期时间（即延迟时间）
  > - **订阅过期事件**：通过订阅 `__keyevent@0__:expired` 频道，监听过期事件
  > - **处理任务**：从处理队列（如 List）中消费任务

| **方案**                   | **优点**                        | **缺点**                      | **适用场景**                 |
| :------------------------- | :------------------------------ | :---------------------------- | :--------------------------- |
| **有序集合（Sorted Set）** | 支持精确时间控制 可批量处理任务 | 需要轮询，资源消耗较大        | 高精度延迟任务（如定时调度） |
| **过期事件监听**           | 无轮询开销，事件驱动            | 过期事件可能丢失 无法批量处理 | 简单延迟任务（如会话超时）   |

### 5.8  Redis 单线程高性能

- **纯内存操作，避免磁盘 I/O 瓶颈**：Redis 数据存储在内存中，读写操作直接在内存完成

- **非阻塞 I/O 多路复用**：通过 `epoll`（Linux）、`kqueue`（BSD）等系统调用，单线程监听多个 Socket 事件
- **高效数据结构与算法**

- **异步持久化机制**

### 5.9 应用

- **库存管理**

  - **预扣库存**：
      - Redis 原子操作扣减库存（`DECR`），避免超卖。
      - 异步同步到数据库（通过消息队列确保最终一致性）。

  - **库存分桶**：
      - 将库存拆分为多个 Key（如 `stock:product_1001:1` ~ `stock:product_1001:10`），分散热点。

  - **库存回滚**：
      - 支付超时后，通过定时任务回滚 Redis 库存。


- **秒杀与高并发**

  - **流量削峰**：
      - 使用 Redis 计数器限制用户请求频率。
      - 请求排队：Redis List 或 Stream 实现队列，异步处理订单。

  - **分布式锁**：
      - 使用 `SET key value NX EX` 实现锁，避免重复下单。
      - 问题：锁超时导致并发问题（需结合 WatchDog 续期）。


- **订单与交易**

  - **订单唯一性**：
      - 使用 Redis 全局唯一 ID（`INCR` 或雪花算法）。

  - **购物车**：
      - 使用 Hash 存储用户购物车（`hset cart:user_1001 product_2001 2`）。


- **数据一致性**

  - **缓存与数据库双写**：
      - 策略：先更新数据库，再删除缓存（延迟双删避免脏数据）。
      - 问题：缓存删除失败导致不一致（通过重试机制或订阅 Binlog 同步）。

  - **最终一致性**：
      - 通过消息队列（如 Kafka）异步同步数据。


- **实时统计与监控**

  - **排行榜**：
      - 使用 ZSet 实时统计商品销量 Top 10。

  - **用户行为分析**：
      - 使用 BitMap 记录用户签到，HyperLogLog 统计 UV


## 6、hbase

### 6.1 库存快照

- **存储架构设计**

    ```
    graph LR
        A[实时库存] --> B[RocksDB本地存储]
        B --> C[定时快照]
        C --> D[OSS持久化存储]
        D --> E[快速恢复通道]
    ```

- **快照生成策略**

    ```python
    # 快照生成逻辑（Python伪代码）
    class SnapshotManager:
        def __init__(self):
            self.wal = WriteAheadLog()  # 预写日志
            self.current_snapshot = None
            
        def apply_operation(self, op):
            self.wal.append(op)  # 先写日志
            self.memtable.apply(op)  # 更新内存表
            
            # 触发快照条件
            if self.wal.size() > 100000 or time.time() - last_snapshot > 3600:
                self.create_snapshot()
        
        def create_snapshot(self):
            # 冻结内存表并持久化
            new_snapshot = self.memtable.freeze()
            self.save_to_oss(new_snapshot)
            self.current_snapshot = new_snapshot
            self.wal.clear()  # 清理旧日志
    ```

- **关键技术指标**

    | 指标项       | 目标值          | 实现手段                    |
    | :----------- | :-------------- | :-------------------------- |
    | 快照延迟     | <5秒（关键SKU） | 内存表分片冻结              |
    | 恢复时间     | <30秒（百万级） | 并行加载+索引优化           |
    | 存储压缩率   | >70%            | ZSTD压缩算法                |
    | 版本保留策略 | 最近7天+关键点  | 时间窗口+事件触发双维度管理 |

### 6.2 核心优势

- LSM-Tree 结构适配写密集型场景：高频写入、顺序写入
- 嵌入式特性减少延迟，提升访问速度
- 数据压缩和存储效率
- 崩溃恢复机制和可靠性，**多版本快照管理**

### 6.3 对比 rocksdb

| **维度**       | **RocksDB**              | **HBase**                         |
| :------------- | :----------------------- | :-------------------------------- |
| **存储模式**   | 嵌入式本地存储（单进程） | 分布式集群存储（多节点协同）      |
| **数据模型**   | 键值存储（Key-Value）    | 列式存储（Column Family）         |
| **写入路径**   | LSM-Tree直接落盘         | 先写HLog→MemStore→定期Flush到HDFS |
| **一致性保证** | 单机ACID                 | 最终一致性（基于ZooKeeper协调）   |
| **访问延迟**   | 微秒级（本地磁盘访问）   | 毫秒级（需网络跳转）              |
| **扩展方式**   | 垂直扩展（单机性能优化） | 水平扩展（增加RegionServer节点）  |

### 6.4 概览

机器配置：64C-256G-16320G，其中 256G 的一半给了hdfs一半给了hbase，128G 的一部分给了MemStore一部分给了blockcache

- 分表：单表最多两个 family、每个 family 最多20个 qualifer
- 数据有效期：默认表级别的有效期为两天

- compaction：每天6点40进行一次 compaction，且之后不允许 bulkload 写入

---

- **存储引擎**：
  - 基于LSM树（Log-Structured Merge Tree）：数据先写入内存（MemStore），再合并成HFile持久化到HDFS。
  - 写优化：顺序写、批量合并。
- **读写流程**：
  - **写流程**：Client → ZooKeeper → RegionServer → MemStore（WAL预写日志） → HFile。
  - **读流程**：Client → RegionServer → BlockCache（缓存热数据） → MemStore + HFile合并结果

---

以下是两者的对比:

1. 数据模型：HBase 是一种列式存储的数据库，而 RocksDB 是 key-value 的
2. 使用场景：HBase 适用于处理大数据，查询操作比较频繁的情况。而 RocksDB 适用于在 SSD 等硬盘上，存储 Key-Value 类型的数据
3. 性能：RocksDB 的读写性能会更好一些
4. 依赖环境：Hbase 基于 Hadoop，环境依赖较大，而 RocksDB 是一种嵌入式数据库，独立性更强
5. 扩展性：HBase 具有很好的水平扩展性，适合处理 PB 级别以上的数据，RocksDB 具备垂直扩展性，适用于存储 TB 级别以下的数据

<img src="../pics/hbase/hbase_152.png">

### 6.5  数据模型与架构

- **数据模型**：
    - **表（Table）**：由行（Row）和列（Column）组成。
    - **行键（RowKey）**：唯一标识一行，按字典序排序，设计需避免热点。
    - **列族（Column Family）**：物理存储单元，同一列族的数据存储在同一个HFile中。
    - **时间戳（Timestamp）**：支持多版本数据，按时间倒序排列。
    
    > **`cell`(单元格)**：由五元组(row, column, timestamp, type, value)组成的结构，其中 `(row, column,timestamp, type)` 是K，value字段对应 KV 结构的 V
    >
    > - `type` 表示 `Put/Delete` 这样的操作类型
    > - `timestamp` 代表这个 cell 的版本
- **架构组件**：
    - **HMaster**：负责元数据管理（表结构、Region分配）、负载均衡。
    - **RegionServer**：管理多个Region，处理读写请求。
    - **Region**：表的分片，按RowKey范围划分，可水平扩展。
    - **ZooKeeper**：协调集群状态（RegionServer存活、元数据存储）

### 6.6 核心特性

- **高扩展性**：通过Region分片支持PB级数据。
- **强一致性**：单行事务（ACID）。
- **稀疏存储**：仅存储非空列，适合半结构化数据。
- **多版本控制**：按时间戳保留历史版本数据

### 6.7 性能优化

- **RowKey设计**：
    - 避免热点：散列（Hash前缀）、时间戳反转（如 `reverse(timestamp)`）
    - 查询模式优先：根据查询需求设计RowKey（如 `用户ID_订单ID`）
- **预分区（Pre-splitting）**：避免Region自动拆分导致性能波动
- **缓存机制**：
    - **BlockCache**：缓存HFile数据块（读优化）
    - **MemStore**：写缓存，定期刷写到HFile
- **压缩与编码**：使用Snappy或GZIP压缩HFile，减少存储和IO开销

### 6.8 高频问题

- **LSM树的优缺点**：
    - 优点：高吞吐写入，适合写多读少场景。
    - 缺点：读放大（需合并MemStore和多个HFile）。
- **Region分裂过程**：达到阈值（`hbase.hregion.max.filesize`）后分裂为两个子Region。
- **HBase与RDBMS的区别**：无固定Schema、不支持复杂事务、适合海量数据
- HBase的LSM树结构解决了什么问题？写流程是怎样的？
- 如何设计RowKey以避免热点问题？举例说明电商场景中的应用。
- HBase的Region分裂和合并过程是如何触发的？
- HBase如何实现多版本控制？如何清理过期数据？
- HBase与HDFS的关系是什么？为什么HBase不直接替代HDFS？
- 在库存场景中，如何用HBase实现实时更新和历史追溯？
- HBase的Get和Scan操作有什么区别？如何优化Scan性能？
- 什么是协处理器（Coprocessor）？在电商中有哪些应用场景？
- HBase如何保证数据的高可用性？（HDFS副本、Region副本）
- 如何通过Phoenix在HBase上实现SQL查询？

### 6.9 应用

#### 1. **库存管理**

- **实时库存更新**：
    - 利用HBase的高吞吐写入能力，记录库存变更流水（如 `RowKey=商品ID_时间戳`）。
    - 结合Redis缓存实时查询库存（HBase存储全量流水，Redis缓存当前值）。
- **库存历史追溯**：
    - 利用多版本特性，按时间戳查询库存变更记录。
- **热点商品优化**：
    - **RowKey散列**：将热门商品的RowKey添加随机前缀（如 `商品ID % 10_商品ID`），分散到不同Region。

#### **2. 订单与交易流水**

- **海量订单存储**：
    - 设计RowKey为 `用户ID反转_订单时间戳`，支持按用户维度快速查询。
    - 使用列族分离冷热数据（如订单基础信息 vs. 物流详情）。
- **订单状态追踪**：
    - 通过HBase的Get操作快速查询单条订单详情。
    - 利用Filter按条件扫描（如状态为“未支付”的订单）。

#### **3. 用户行为分析**

- **行为日志存储**：
    - 存储用户点击、搜索、购买行为（RowKey=用户ID_行为时间戳）。
    - 结合Phoenix实现SQL化查询（如统计用户活跃度）。
- **实时推荐**：
    - 基于HBase存储用户画像（标签、偏好），实时匹配推荐规则。

#### **4. 供应链数据聚合**

- **分布式统计**：
    - 利用MapReduce或Spark on HBase计算库存周转率、供应商履约率。
    - 通过协处理器（Coprocessor）实现局部聚合，减少网络开销。
- **物流轨迹存储**：
    - 按订单ID+时间戳存储物流节点，支持时间范围查询





熟悉HBase的MemStore刷写机制、Compaction流程。

如何通过预分区、RowKey设计优化性能

HBase与Kafka（实时数据摄入）、Spark（离线分析）的协同使用



## 7、kafka

### 7.1 变更流水核心点

- **顺序保证**：通过Kafka分区键（SKU哈希）保证同一商品顺序性

- **幂等处理**：

    ```java
    // 消费者幂等处理示例
    public void handleMessage(InventoryChange change) {
        if (redis.setnx("change_id:"+change.getChangeId(), "1")) {
            // 实际处理逻辑
            processChange(change);
            redis.expire("change_id:"+change.getChangeId(), 86400);
        }
    }
    ```

- **压缩存储**：

    - 实时流水：Parquet列式存储（Kafka→HDFS）
    - 归档流水：ZSTD压缩+冷存储

### 7.2 架构与核心组件

- **核心角色**：
    - **Broker**：Kafka 服务节点，负责消息存储和转发。
    - **Topic**：消息的逻辑分类（如 `order_events`、`inventory_updates`）。
    - **Partition**：Topic 的物理分片，支持并行读写和水平扩展。
    - **Producer**：消息生产者，按分区策略（Round-Robin、Key Hash）发送消息。
    - **Consumer**：消息消费者，通过消费者组（Consumer Group）实现负载均衡。
    - **ZooKeeper**：管理集群元数据（Broker 状态、Topic 配置）。
- **核心特性**：
    - 高吞吐：顺序磁盘 I/O + 零拷贝（Zero-Copy）技术。
    - 持久化：消息按时间保留（默认 7 天），支持重放。
    - 分布式：Partition 多副本（Replica）机制，Leader-Follower 同步

### 7.3 消息传递语义

**消息可靠性**：

- **At Least Once**（至少一次）：Producer 重试 + Consumer 手动提交 Offset。
- **Exactly Once**（精确一次）：需事务支持（Producer 事务 API）或幂等性设计。
- **At Most Once**（至多一次）：Producer 不重试，Consumer 自动提交 Offset

### 7.4 高可用与容灾

- **副本机制**：
    - Leader 处理读写请求，Follower 异步/同步复制数据。
    - **ISR（In-Sync Replicas）**：与 Leader 保持同步的副本集合。
    - 故障恢复：Leader 宕机时，从 ISR 中选举新 Leader。
- **数据一致性**：
    - **acks 参数**：
        - `acks=0`：不等待确认（可能丢失数据）。
        - `acks=1`：Leader 确认（默认，平衡性能与可靠性）。
        - `acks=all`：所有 ISR 副本确认（最高可靠性）

### 7.5 性能优化

- **分区策略**：
    - 合理分区数：根据吞吐量和消费者并行度设置（避免过多小文件）。
    - 分区键（Key）设计：保证相同 Key 的消息写入同一分区（如订单 ID）。
- **批量与压缩**：
    - 批量发送（`linger.ms` 和 `batch.size`）减少网络开销。
    - 消息压缩（Snappy、GZIP）减少传输数据量。
- **消费者组**：
    - 分区分配策略：Range、Round-Robin、StickyAssignor。
    - 消费者延迟监控：通过 `Consumer Lag` 检测处理滞后

### 7.6 高频问题

- Kafka 为什么吞吐量高？（顺序 I/O、批量处理、零拷贝）
- 如何保证消息顺序性？（单分区内有序，多分区需业务逻辑处理）
- 如何解决重复消费？（幂等性设计、数据库唯一约束）
- 分区数如何影响性能？（分区数过多增加元数据开销）
- Kafka 如何保证消息不丢失？（Producer acks、Broker 副本、Consumer 手动提交）
- 如何实现 Kafka 消息的全局有序？（单分区写入 + 单消费者）
- 消费者组中消费者数量多于分区数会发生什么？（部分消费者闲置）
- 分区 Leader 选举的流程是怎样的？（基于 ZooKeeper 或 KRaft）
- 如何监控 Kafka 集群的健康状态？（JMX 指标、Consumer Lag、Broker 日志）
- 为什么 Kafka 适合日志场景？（高吞吐、持久化、顺序读写）
- 如何解决 Kafka 消费者重复消费？（幂等处理、事务）
- Kafka 与 RabbitMQ 的核心区别是什么？（吞吐量、协议、设计目标）
- 如何设计一个支持百万级 TPS 的 Kafka 集群？（分区规划、硬件优化、副本策略）
- 在电商场景中，如何用 Kafka 实现订单和库存的最终一致性？



### 7.7 应用

#### **订单与交易**

- **订单异步处理**：
    - 用户下单后，订单消息写入 `order_created` Topic，由下游服务异步处理（库存扣减、支付回调、物流通知）。
    - 优势：解耦系统，提高吞吐量。
- **订单状态流转**：
    - 通过多个 Topic（如 `order_paid`、`order_shipped`）实现状态机驱动，保证最终一致性。

#### **2. 库存管理**

- **实时库存更新**：
    - 库存变更（扣减、回滚）通过 `inventory_updates` Topic 广播，多个服务订阅更新（如数据库、缓存）。
    - 示例：用户支付成功后，发送库存扣减消息，确保缓存（Redis）与数据库（MySQL）一致。
- **库存流水溯源**：
    - 所有库存操作记录到 Kafka，供后续对账或审计（如 `inventory_audit` Topic）。

#### **3. 日志与监控**

- **用户行为采集**：
    - 用户点击、搜索、加购行为实时写入 Kafka（如 `user_behavior` Topic），供 Flink/Spark 实时分析。
- **系统监控告警**：
    - 服务日志（如错误日志、性能指标）集中写入 Kafka，对接 ELK 或 Prometheus 实现监控。

#### **4. 流量削峰与错峰处理**

- **秒杀场景**：
    - 瞬时高并发请求写入 Kafka，下游服务按可控速率消费，避免压垮数据库。
    - 示例：用户抢购请求先进入 `seckill_requests` Topic，由库存服务批量处理。
- **批量任务调度**：
    - 定时任务（如每日库存盘点）通过 Kafka 触发，避免集中执行导致资源争抢。

#### **5. 数据一致性保障**

- **跨系统事务**：
    - 通过 Kafka 事务消息实现分布式事务（如扣减库存后发送支付消息，失败则回滚）。
    - 方案：本地事务表 + Kafka 事务 API（两阶段提交）





熟悉 Kafka 的 Log 存储结构、网络模型（Reactor 模式）、ISR 同步机制

如何通过 Kafka 解决高并发、数据一致性等问题